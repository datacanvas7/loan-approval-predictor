# -*- coding: utf-8 -*-
"""credit_risk_scoring_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F56ye25nuawRlR9Ab6UzuXAj9HUHWRWF

# Credit Risk Scoring (Loan Approval Prediction)
ðŸ“˜ Introduction & Problem Statement:
In financial institutions, lending to unqualified applicants increases the risk of default and non-performing assets (NPAs). Traditional rule-based systems can be inefficient in identifying high-risk applicants.

ðŸŽ¯ Business Objective:
To develop a credit risk model that predicts loan approval outcomes based on applicant profiles, improving lending decisions and minimizing risk exposure.

## 01- Import libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## 02- Load dataset"""

df = pd.read_csv('train_data.csv')
df.head()

"""# 03- EDA Steps"""

df.shape

df.describe()

df.info()

df.isnull().sum()

df.duplicated().sum()

df.nunique()

df.columns

df.fillna(0, inplace=True)
print("NaNs has been replaced with 0")

# Convert all column names to lowercase
df.columns = df.columns.str.lower()

df.columns

df.duplicated().sum()

"""# 04- Data Wrangling"""

df["combined_income"]= df['applicantincome'] + df['coapplicantincome']
df["combined_income"].head()

# Calculate mean values (excluding 0s to avoid skewing)
loan_amount_mean = df[df['loanamount'] != 0]['loanamount'].mean()
loan_term_mean = df[df['loan_amount_term'] != 0]['loan_amount_term'].mean()

# Replace 0 values with the calculated means
df['loanamount'] = np.where(df['loanamount'] == 0, loan_amount_mean, df['loanamount'])
df['loan_amount_term'] = np.where(df['loan_amount_term'] == 0, loan_term_mean, df['loan_amount_term'])

df.head()

"""# 05- Feature Engineering & Preprocessing"""

df['loan_id_extracted'] = df['loan_id'].str.replace('LP', '').astype(int)

# Creates a numeric-encoded copy of the DataFrame with extracted loan IDs for correlation analysis while preserving the original data.
from sklearn.preprocessing import LabelEncoder

# Create a copy to avoid modifying original dataframe
df_corr = df.copy()

# First ensure we've created the loan_id_extracted column if not already done
if 'loan_id_extracted' not in df_corr.columns:
    df_corr['loan_id_extracted'] = df_corr['loan_id'].str.extract('(\d+)').astype(int)

# Encode categorical variables
for col in df_corr.select_dtypes(include=['object']).columns:
    if col != 'loan_id_extracted':  # Skip the original Loan_ID column
        le = LabelEncoder()
        df_corr[col] = le.fit_transform(df_corr[col].astype(str))

from sklearn.preprocessing import StandardScaler

# Select numerical columns to scale (exclude categoricals and target)
num_cols = ['applicantincome', 'coapplicantincome', 'loanamount', 'loan_amount_term']
scaler = StandardScaler()

# Fit on training data ONLY, then transform both train/test
df[num_cols] = scaler.fit_transform(df[num_cols])

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))  # Default is (0,1)
df[num_cols] = scaler.fit_transform(df[num_cols])

df.head()

# One-hot encode categoricals first
cat_cols = ['gender', 'married', 'education', 'self_employed']
df = pd.get_dummies(df, columns=cat_cols)

# First get list of categorical columns before one-hot encoding
cat_cols = ['gender', 'married', 'education', 'self_employed', 'dependents', 'property_area']

# Create correlation dataframe BEFORE one-hot encoding
df_corr = df.copy()

# Convert categorical columns to numerical codes
for col in cat_cols:
    if col in df_corr.columns:  # Check if column exists
        df_corr[col] = pd.factorize(df_corr[col])[0]

"""# 06- Data Visualization"""

# Boxplots for numerical variables
num_cols = ['combined_income', 'loanamount', 'loan_amount_term']
plt.figure(figsize=(15,10))
for i, col in enumerate(num_cols, 1):
    plt.subplot(2,2,i)
    sns.boxplot(y=df[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

# Treat outliers (cap at 99th percentile)
for col in ['combined_income', 'loanamount']:
    upper_limit = df[col].quantile(0.99)
    df[col] = np.where(df[col]>upper_limit, upper_limit, df[col])

# Numerical variables
plt.figure(figsize=(15,10))
for i, col in enumerate(num_cols, 1):
    plt.subplot(2,2,i)
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

# Loan Status vs other variables
# First get the dummy column names that were created from the original categorical columns
dummy_cols = [col for col in df.columns if any(cat in col for cat in ['gender', 'married', 'education', 'self_employed', 'dependents', 'property_area'])]

plt.figure(figsize=(15,25))
for i, col in enumerate(dummy_cols, 1):
    plt.subplot(4,2,i)
    sns.countplot(data=df, x=col, hue='loan_status')
    plt.title(f'Loan Status by {col}')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Income vs Loan Status
plt.figure(figsize=(12,6))
sns.boxplot(data=df, x='loan_status', y='combined_income')
plt.title('Applicants Income by Loan Status')
plt.show()

import plotly.express as px

# Interactive plot using existing columns
fig = px.scatter(df, x='applicantincome', y='loanamount', color='loan_status',
                 hover_data=['property_area', 'education_Graduate', 'education_Not Graduate'],
                 title='Income vs Loan Amount by Approval Status')
fig.show()

# Create Total Income feature
df['income_to_loan_ratio'] = df['combined_income'] / df['loanamount']

# Analyze new metrics
plt.figure(figsize=(12,6))
sns.boxplot(data=df, x='loan_status', y='income_to_loan_ratio')
plt.title('Income to Loan Ratio by Approval Status')
plt.show()

df.head()

# Create correlation matrix only with numeric columns
numeric_df = df.select_dtypes(include=['int64', 'float64'])

plt.figure(figsize=(12,8))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')
plt.title('Correlation Matrix (Numeric Features Only)')
plt.tight_layout()
plt.show()

# Now create correlation matrix
plt.figure(figsize=(12,8))
# Select only numerical columns for correlation
numerical_df = df_corr.select_dtypes(include=['number'])
sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')
plt.title('Correlation Matrix (Numerical Features Only)')
plt.tight_layout()
plt.show()

"""# 07- Model Training"""

# convert target to binary
df['loan_status'] = df['loan_status'].map({'Y': 1, 'N': 0}).astype(int)

import pandas as pd
from sklearn.model_selection import train_test_split

# Create key features
df['income_gt_4000'] = (df['combined_income'] > 4000).astype(int)

# Select key features + target
features = ['income_gt_4000', 'credit_history', 'property_area']
X = pd.get_dummies(df[features], columns=['property_area'], drop_first=True)
y = df['loan_status']

# Split data (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(random_state=42),
    "XGBoost": XGBClassifier(random_state=42),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(random_state=42)
}

# Train and evaluate each model
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f"{name} Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred))
    print("----------------------------------")

# Show results
print("\nModel Comparison:")
for name, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):
    print(f"{name}: {acc:.4f}")

"""# 08- Model Evaluation"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd

# Store results in a DataFrame
results = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1'])

for name, model in models.items():
    # Train and predict
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Store results
    results.loc[len(results)] = [name, accuracy, precision, recall, f1]

# Display all results
print("\n=== Model Performance Comparison ===")
print(results.sort_values('Accuracy', ascending=False))

# Identify best model
best_model = results.loc[results['Accuracy'].idxmax()]
print("\n=== Best Model ===")
print(f"Model: {best_model['Model']}")
print(f"Accuracy: {best_model['Accuracy']:.4f}")
print(f"F1-Score: {best_model['F1']:.4f}")

# Visual comparison
results.set_index('Model').sort_values('Accuracy').plot(kind='barh', figsize=(10,6))
plt.title('Model Performance Comparison')
plt.xlabel('Score')
plt.show()

"""# 09- Hyperparameter Tuning

- Hyperparameter tuning is used to find the best model settings that improve accuracy and prevent overfitting.
- It optimizes model performance by testing different configurations.
"""

from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score
import numpy as np

"""Define Search Spaces for Each Model"""

param_grids = {
    "Logistic Regression": {
        'C': np.logspace(-4, 4, 20),
        'penalty': ['l1', 'l2', 'elasticnet'],
        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']
    },
    "Random Forest": {
        'n_estimators': [50, 100, 200, 300],
        'max_depth': [None, 5, 10, 20],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2']
    },
    "XGBoost": {
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 6, 9],
        'learning_rate': [0.01, 0.1, 0.2],
        'subsample': [0.6, 0.8, 1.0],
        'colsample_bytree': [0.6, 0.8, 1.0]
    },
    "KNN": {
        'n_neighbors': range(3, 21, 2),
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean', 'manhattan', 'minkowski']
    },
    "SVM": {
        'C': [0.1, 1, 10, 100],
        'gamma': [1, 0.1, 0.01, 0.001],
        'kernel': ['rbf', 'poly', 'sigmoid']
    }
}

"""Tuning Implementation Using Randomized Search (Faster)"""

def tune_models_randomized(models, param_grids, X_train, y_train, n_iter=50, cv=5):
    best_models = {}

    for name, model in models.items():
        print(f"\n=== Tuning {name} ===")

        # Use randomized search
        random_search = RandomizedSearchCV(
            estimator=model,
            param_distributions=param_grids[name],
            n_iter=n_iter,
            cv=cv,
            scoring='accuracy',
            n_jobs=-1,
            random_state=42
        )

        random_search.fit(X_train, y_train)
        best_models[name] = random_search.best_estimator_

        print(f"Best params: {random_search.best_params_}")
        print(f"Best score: {random_search.best_score_:.4f}")

    return best_models

best_models_random = tune_models_randomized(models, param_grids, X_train, y_train)

"""Tuning Implementation Using Grid Search (More Thorough but Slower)"""

def tune_models_grid(models, param_grids, X_train, y_train, cv=5):
    best_models = {}

    for name, model in models.items():
        print(f"\n=== Tuning {name} ===")

        # Use grid search
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grids[name],
            cv=cv,
            scoring='accuracy',
            n_jobs=-1
        )

        grid_search.fit(X_train, y_train)
        best_models[name] = grid_search.best_estimator_

        print(f"Best params: {grid_search.best_params_}")
        print(f"Best score: {grid_search.best_score_:.4f}")

    return best_models

# Use this only if your dataset is small or you have time
# best_models_grid = tune_models_grid(models, param_grids, X_train, y_train)

""" Evaluation of Tuned Models"""

def evaluate_models(models, X_test, y_test):
    results = {}

    for name, model in models.items():
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        results[name] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }

        print(f"\n=== {name} ===")
        print(f"Accuracy: {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall: {recall:.4f}")
        print(f"F1 Score: {f1:.4f}")
        print(classification_report(y_test, y_pred))

    return results

# Evaluate the tuned models
tuned_results = evaluate_models(best_models_random, X_test, y_test)

"""# 10- Saving Model"""

from joblib import dump

# Save all models with their exact names
for model_name, model in models.items():
    dump(model, f'{model_name.replace(" ", "_")}.joblib')

"""# 11- Conclusion & Business Insights
ðŸ”¹ Loan Approval is Highly Influenced By:
- Credit History (Most critical factor)
- Applicant Income (Higher income â†’ Higher approval chances)
- Loan Amount vs. Income Ratio (Lower ratio â†’ Better approval odds)
- Co-applicant Income (Improves approval likelihood)

ðŸ”¹ Best Model Choice:

- XGBoost (if highest accuracy is needed).

- Random Forest (if interpretability is important).

- Logistic Regression (if probability estimates are needed for risk scoring).

---
"""